{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63017020-1b9c-4ec7-b695-f22425ff3875",
   "metadata": {},
   "source": [
    "# TMA4267 - DOE\n",
    "Code used for assignment 3 in TMA4267."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "521e6a74-50d3-4b6b-8511-b62409603d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e2cf2c-17ce-44e9-bf7a-c718c8be9b1f",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "We start by loading the data, remove missing values, and divide origin into three columns (USA, Europe and Japan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5282a214-8100-4e77-b519-5ff3f6fb40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "dataset = pd.read_csv(url, names=column_names, na_values='?', comment='\\t', sep=' ', skipinitialspace=True)\n",
    "dataset = dataset.dropna()\n",
    "dataset['Origin'] = dataset['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n",
    "dataset = pd.get_dummies(dataset, columns=['Origin'], prefix='', prefix_sep='')\n",
    "\n",
    "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "train_labels = train_features.pop('MPG')\n",
    "test_labels = test_features.pop('MPG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9108341a-4802-41e1-970a-686c2a5ffdbe",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1de7cbbb-d323-47be-9a33-6df69528ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data before we feed it into to the neural network\n",
    "def normalized(x):\n",
    "    return (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "\n",
    "def build_and_compile_model(optim, hid1, hid2, seed):\n",
    "    tf.random.set_seed(seed)\n",
    "    model=Sequential()\n",
    "    model.add(Dense(hid1, input_dim=9, activation='relu'))\n",
    "    model.add(Dense(hid2, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                optimizer=optim)\n",
    "    return model\n",
    "\n",
    "def train(optim, lr, hid1, hid2, seed):\n",
    "    if optim == 'Adam':\n",
    "        dnn_model = build_and_compile_model(tf.keras.optimizers.Adam(lr), hid1, hid2, seed)\n",
    "    elif optim == 'SGD0' or optim == 'SGD':\n",
    "        dnn_model = build_and_compile_model(tf.keras.optimizers.SGD(lr), hid1, hid2, seed)\n",
    "        \n",
    "    # We will train the network for 100 epochs. When the valdiation loss hasn't decreasing for 5 epochs, \n",
    "    # we will stop the training (to reduce overfitting) and use the best model (i.e., the weights of the \n",
    "    # epoch with the lowest validation loss)\n",
    "    callback = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience = 5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    dnn_model.fit(\n",
    "        normalized(train_features),\n",
    "        train_labels,\n",
    "        validation_split=0.25,\n",
    "        verbose=0, epochs= 100, \n",
    "        callbacks = [callback]\n",
    "    )\n",
    "    \n",
    "    # We make predictions on the test set and calculate the MAE\n",
    "    test_pred = dnn_model.predict(normalized(test_features)).flatten()\n",
    "    return np.round(mean_absolute_error(test_labels, test_pred),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50fbef3-34a0-427a-89d5-b1bb7d823124",
   "metadata": {},
   "source": [
    "We will test the different factors (with 2 levels each):\n",
    "1. Optimizer: Adam vs SGD\n",
    "2. Learning rate: 0.01 vs 0.001\n",
    "3. Hidden layer 1: 32 or 64\n",
    "4. Hidden layer 2: 32 or 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9f68d10-64c3-4ef4-a48c-a9f75b629b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 0\n",
      "[2.221, 2.009, 1.923, 2.124, 2.464, 1.879, 1.971, 1.998, 2.284, 1.93, 1.98, 1.915, 2.325, 2.035, 2.016, 1.837]\n",
      "Seed: 1\n",
      "[2.294, 1.799, 1.856, 1.907, 2.337, 1.937, 1.867, 2.105, 2.161, 1.911, 1.807, 1.914, 2.293, 1.983, 2.039, 1.951]\n",
      "Seed: 11\n",
      "[2.267, 1.832, 1.915, 1.876, 2.217, 1.97, 1.948, 1.906, 2.199, 1.926, 1.969, 2.148, 2.233, 1.89, 1.895, 1.939]\n",
      "Seed: 111\n",
      "[2.176, 1.947, 1.905, 1.839, 2.161, 1.885, 2.087, 1.953, 2.161, 1.902, 1.817, 2.0, 2.317, 1.848, 1.982, 1.94]\n"
     ]
    }
   ],
   "source": [
    "seeds = [0, 1, 11, 111]\n",
    "\n",
    "for seed in seeds:\n",
    "    MAE = []\n",
    "    \n",
    "    # Use SGD0 instead of SGD to get it the same length as ADAM (looks nicer)\n",
    "    MAE.append(train('SGD0', 5e-3, 32, 32,seed))\n",
    "    MAE.append(train('Adam', 5e-3, 32, 32,seed))\n",
    "    MAE.append(train('SGD0', 1e-2, 32, 32,seed))\n",
    "    MAE.append(train('Adam', 1e-2, 32, 32,seed))\n",
    "\n",
    "    MAE.append(train('SGD0', 5e-3, 64, 32,seed))\n",
    "    MAE.append(train('Adam', 5e-3, 64, 32,seed))\n",
    "    MAE.append(train('SGD0', 1e-2, 64, 32,seed))\n",
    "    MAE.append(train('Adam', 1e-2, 64, 32,seed))\n",
    "\n",
    "    MAE.append(train('SGD0', 5e-3, 32, 64,seed))\n",
    "    MAE.append(train('Adam', 5e-3, 32, 64,seed))\n",
    "    MAE.append(train('SGD0', 1e-2, 32, 64,seed))\n",
    "    MAE.append(train('Adam', 1e-2, 32, 64,seed))\n",
    "\n",
    "    MAE.append(train('SGD0', 5e-3, 64, 64,seed))\n",
    "    MAE.append(train('Adam', 5e-3, 64, 64,seed))\n",
    "    MAE.append(train('SGD0', 1e-2, 64, 64,seed))\n",
    "    MAE.append(train('Adam', 1e-2, 64, 64,seed))\n",
    "    \n",
    "    print('Seed:', seed)\n",
    "    print(MAE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
